{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = pd.concat([pd.read_csv('Data/2009.csv'), pd.read_csv('Data/2010.csv'), \n",
    " #                 pd.read_csv('Data/2011.csv'), pd.read_csv('Data/2012.csv'), \n",
    "  #                pd.read_csv('Data/2013.csv'), pd.read_csv('Data/2014.csv'), \n",
    "   #               pd.read_csv('Data/2015.csv'), pd.read_csv('Data/2016.csv'), \n",
    "    #              pd.read_csv('Data/2017.csv'), pd.read_csv('Data/2018.csv')])\n",
    "\n",
    "# Read 2018 data only\n",
    "data = pd.read_csv('Data/2010.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert string to DateTime and set as index\n",
    "data.FL_DATE = pd.to_datetime(data.FL_DATE, infer_datetime_format=True)\n",
    "data.set_index('FL_DATE', inplace=True)\n",
    "data.drop(columns='Unnamed: 27', axis=1, inplace=True) # Drop last weird column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop NaN values in the variables we will use in our baseline model\n",
    "data = data[data['TAXI_OUT'].notna()]\n",
    "data = data[data['ORIGIN'].notna()]\n",
    "data = data[data['DEST'].notna()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take first 6 months\n",
    "df = data.loc['2010-01-01':'2010-06-30']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/frederikhartmann/opt/anaconda3/lib/python3.9/site-packages/pandas/core/generic.py:6619: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return self._update_inplace(result)\n"
     ]
    }
   ],
   "source": [
    "# Renaming airline codes to company names\n",
    "# Source: https://en.wikipedia.org/wiki/List_of_airlines_of_the_United_States\n",
    "\n",
    "df['OP_CARRIER'].replace({\n",
    "    'UA':'United Airlines',\n",
    "    'AS':'Alaska Airlines',\n",
    "    '9E':'Endeavor Air',\n",
    "    'B6':'JetBlue Airways',\n",
    "    'EV':'ExpressJet',\n",
    "    'F9':'Frontier Airlines',\n",
    "    'G4':'Allegiant Air',\n",
    "    'HA':'Hawaiian Airlines',\n",
    "    'MQ':'Envoy Air',\n",
    "    'NK':'Spirit Airlines',\n",
    "    'OH':'PSA Airlines',\n",
    "    'OO':'SkyWest Airlines',\n",
    "    'VX':'Virgin America',\n",
    "    'WN':'Southwest Airlines',\n",
    "    'YV':'Mesa Airline',\n",
    "    'YX':'Republic Airways',\n",
    "    'AA':'American Airlines',\n",
    "    'DL':'Delta Airlines'\n",
    "},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.ORIGIN == 'JFK']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fs/10_w6dn131d7nmw8myr18l6r0000gn/T/ipykernel_45648/2885194547.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  delays['DEP_TIME'] = delays['DEP_TIME'].astype(int)\n"
     ]
    }
   ],
   "source": [
    "delays = df[['CARRIER_DELAY', 'DEP_TIME']]\n",
    "delays['DEP_TIME'] = delays['DEP_TIME'].astype(int)\n",
    "\n",
    "preps = []\n",
    "for i in range(len(delays['DEP_TIME'])):\n",
    "    # Zero fill values\n",
    "    dep_time_val = str(delays['DEP_TIME'].iloc[i]).zfill(4)\n",
    "    # If flight at 24:00, set that as 00:00\n",
    "    if dep_time_val == str(2400):\n",
    "        dep_time_act = datetime.datetime.strptime('0000','%H%M').strftime('%H:%M')\n",
    "    else:\n",
    "        dep_time_act = datetime.datetime.strptime(dep_time_val,'%H%M').strftime('%H:%M')\n",
    "    \n",
    "\n",
    "    # append\n",
    "    preps.append(dep_time_act)\n",
    "\n",
    "# Drop and add corrected times\n",
    "df.drop(columns=['DEP_TIME'])\n",
    "df['DEP_TIME'] = preps\n",
    "df['DEP_TIME'] = pd.to_datetime(df['DEP_TIME'], format='%H:%M') # Convert to datetime\n",
    "\n",
    "# Convert FL time to column\n",
    "df = df.reset_index(level=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "comb_date = []\n",
    "# Loop through all to combine dates and time\n",
    "for i in range(len(df['DEP_TIME'])):\n",
    "\n",
    "    # Get date and time\n",
    "    date = datetime.datetime.date(df['FL_DATE'].iloc[i])\n",
    "    time = datetime.datetime.time(df['DEP_TIME'].iloc[i])\n",
    "\n",
    "    # Get combined as a string\n",
    "    comb = datetime.datetime.combine(date, time).strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "    #append\n",
    "    comb_date.append(comb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add column, and remove DEP_TIME and FL_DATE\n",
    "df['DATE_TIME'] = pd.to_datetime(comb_date)\n",
    "# Get dep time as time only\n",
    "df['DEP_TIME'] = pd.to_datetime(df['DEP_TIME'], format='%H:%M').dt.time # Convert to datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move it to the front of the data frame\n",
    "dates = df.pop('DATE_TIME')\n",
    "df.insert(0, 'DATE_TIME', dates)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WEATHER DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load weather data\n",
    "df_weather_all = pd.read_csv('Data/Weather.csv')\n",
    "# Select only relevant features\n",
    "df_weather = df_weather_all[[\"NAME\",\"DATE\",\"HLY-TEMP-NORMAL\",\"HLY-WIND-AVGSPD\"]]\n",
    "# Select only JFK airport and from January 1st to July 1st\n",
    "df_weather= df_weather[(df_weather[\"NAME\"] == \"JFK INTERNATIONAL AIRPORT, NY US\") & (df_weather[\"DATE\"] < '07-01T00:00:00')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the format of DATE to datetime\n",
    "df_weather[\"DATE\"] = pd.to_datetime(df_weather[\"DATE\"],format='%m-%dT%H:%M:%S',infer_datetime_format='%d-%m-%H')\n",
    "# Change the format to month - day - hour\n",
    "df_weather[\"DATE\"] = df_weather[\"DATE\"].dt.strftime(\"%m-%d-%H\")\n",
    "# Change NAME to just JFK\n",
    "df_weather[\"NAME\"] = 'JFK'\n",
    "# Reset index\n",
    "df_weather = df_weather.reset_index().drop('index',axis=1)\n",
    "df_weather\n",
    "\n",
    "# Select interesting features\n",
    "df = df[[\"FL_DATE\",\"OP_CARRIER\",\"DEP_TIME\",\"TAXI_OUT\", \"CARRIER_DELAY\"]]\n",
    "\n",
    "# Now we must merge df_weather and df\n",
    "df[\"TEMP\"] = 0\n",
    "df[\"WIND\"] = 0\n",
    "\n",
    "for i in range(len(df)):\n",
    "    # Filter out the month, day and hour \n",
    "    hour = df[\"DEP_TIME\"][i].strftime(\"%H\")\n",
    "    monthday = df[\"FL_DATE\"][i].strftime(\"%m-%d\")\n",
    "    \n",
    "    if monthday+'-'+hour == '01-01-00':\n",
    "        continue\n",
    "    else:\n",
    "        # Find temp in df_weather corresponding to month, day and hour\n",
    "        df.iloc[i,-2] = df_weather[df_weather[\"DATE\"] == monthday+'-'+hour].iloc[0,2]\n",
    "        # Find wind in df_weather corresponding to month, day and hour\n",
    "        df.iloc[i,-1] = df_weather[df_weather[\"DATE\"] == monthday+'-'+hour].iloc[0,3]\n",
    "        \n",
    "# The hour of january 1st is not included in weather data. Therefore we drop the flights occurring in that time\n",
    "df = df[df.TEMP > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot encode the carriers\n",
    "y = pd.get_dummies(df.OP_CARRIER, prefix='OP_CARRIER')\n",
    "# Drop column B as it is now encoded\n",
    "df.drop(columns='OP_CARRIER', inplace=True)\n",
    "# Join the encoded df\n",
    "df = df.join(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape before: (6338168, 26) \n",
      " Shape after: (54180, 16)\n"
     ]
    }
   ],
   "source": [
    "# Compare shape to see effect of preprocessing\n",
    "print('Shape before:',data.shape,'\\n Shape after:',df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save as new dataframe\n",
    "df.to_csv('Data/data_pre.csv')\n",
    "df_weather.to_csv('Data/weather_pre.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "24a209cba9a9ab1c5651cc7484a1d32e0cd27295ead7dd257cd5c216422a5a45"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
