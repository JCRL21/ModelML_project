{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jcrl\\miniconda3\\envs\\ModelML\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd   \n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import itertools\n",
    "\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "from pyro.contrib.autoguide import AutoDiagonalNormal, AutoMultivariateNormal\n",
    "from pyro.infer import MCMC, NUTS, HMC, SVI, Trace_ELBO\n",
    "from pyro.optim import Adam, ClippedAdam\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "# fix random generator seed (for reproducibility of results)\n",
    "np.random.seed(42)\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "# matplotlib options\n",
    "palette = itertools.cycle(sns.color_palette())\n",
    "plt.style.use('ggplot')\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (16, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Data/data_pre.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop([\"Unnamed: 0\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"DEP_TIME\"] = pd.to_datetime(df[\"DEP_TIME\"]).dt.hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"FL_DATE\"]=pd.to_datetime(df[\"FL_DATE\"]).dt.dayofyear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(54180, 15)\n"
     ]
    }
   ],
   "source": [
    "X = df.drop([\"DEP_DELAY\"], axis=1)\n",
    "print(X.shape)\n",
    "X = X.to_numpy()\n",
    "\n",
    "\n",
    "y = df[\"DEP_DELAY\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "# standardize input features\n",
    "X_train_mean = X_train.mean(axis=0)\n",
    "X_train_std = X_train.std(axis=0)\n",
    "X_train = (X_train - X_train_mean) / X_train_std\n",
    "\n",
    "X_test_mean = X_test.mean(axis=0)\n",
    "X_test_std = X_test.std(axis=0)\n",
    "X_test = (X_test - X_test_mean) / X_test_std\n",
    "\n",
    "# standardize target\n",
    "y_train_mean = y_train.mean()\n",
    "y_train_std = y_train.std()\n",
    "y_train = (y_train - y_train_mean) / y_train_std\n",
    "\n",
    "y_test_mean = y_test.mean()\n",
    "y_test_std = y_test.std()\n",
    "y_test = (y_test - y_test_mean) / y_test_std\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_error(trues, predicted):\n",
    "    corr = np.corrcoef(predicted, trues)[0,1]\n",
    "    mae = np.mean(np.abs(predicted - trues))\n",
    "    rae = np.sum(np.abs(predicted - trues)) / np.sum(np.abs(trues - np.mean(trues)))\n",
    "    rmse = np.sqrt(np.mean((predicted - trues)**2))\n",
    "    r2 = max(0, 1 - np.sum((trues-predicted)**2) / np.sum((trues - np.mean(trues))**2))\n",
    "    return corr, mae, rae, rmse, r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CorrCoef: -0.011\n",
      "MAE: 3533056383.960\n",
      "RMSE: 5206834839.693\n",
      "R2: 0.000\n"
     ]
    }
   ],
   "source": [
    "regr = linear_model.LinearRegression()\n",
    "regr.fit(X_train, y_train)\n",
    "y_hat = regr.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "corr, mae, rae, rmse, r2 = compute_error(y_test, y_hat)\n",
    "print(\"CorrCoef: %.3f\\nMAE: %.3f\\nRMSE: %.3f\\nR2: %.3f\" % (corr, mae, rmse, r2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(X, obs=None):\n",
    "    \n",
    "    alpha = pyro.sample(\"alpha\", dist.Normal(0., 1.))                   # Prior for the bias/intercept\n",
    "    beta  = pyro.sample(\"beta\", dist.Normal(torch.zeros(X.shape[1]), \n",
    "                                            torch.ones(X.shape[1])).to_event())    # Priors for the regression coeffcients\n",
    "    sigma = pyro.sample(\"sigma\", dist.HalfCauchy(5.))                   # Prior for the variance\n",
    "    with pyro.plate(\"data\"):\n",
    "        y = pyro.sample(\"y\", dist.Normal(alpha + X.matmul(beta), sigma), obs=obs)\n",
    "        \n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for Pyro model\n",
    "X_train_small = torch.tensor(X_train).float()\n",
    "y_train_small = torch.tensor(y_train).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sample: 100%|██████████| 1200/1200 [13:27,  1.49it/s, step size=7.33e-03, acc. prob=0.928]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                mean       std    median      5.0%     95.0%     n_eff     r_hat\n",
      "     alpha     -0.00      0.00     -0.00     -0.01      0.01   1298.99      1.00\n",
      "   beta[0]     -0.00      0.02     -0.01     -0.04      0.03    282.69      1.00\n",
      "   beta[1]      0.23      0.01      0.23      0.22      0.24    815.78      1.01\n",
      "   beta[2]      0.12      0.01      0.12      0.11      0.12   1012.76      1.00\n",
      "   beta[3]     -0.04      0.02     -0.04     -0.07     -0.01    297.68      1.00\n",
      "   beta[4]     -0.14      0.01     -0.14     -0.15     -0.13    641.57      1.00\n",
      "   beta[5]      0.06      0.35      0.08     -0.50      0.65    131.71      1.00\n",
      "   beta[6]     -0.00      0.45      0.03     -0.71      0.76    132.04      1.00\n",
      "   beta[7]     -0.00      0.08      0.00     -0.13      0.12    132.05      1.00\n",
      "   beta[8]     -0.01      0.31      0.02     -0.49      0.51    131.89      1.00\n",
      "   beta[9]      0.01      0.10      0.01     -0.16      0.16    132.51      1.00\n",
      "  beta[10]      0.01      0.58      0.06     -0.91      0.99    131.90      1.00\n",
      "  beta[11]      0.01      0.08      0.02     -0.12      0.14    133.81      1.00\n",
      "  beta[12]      0.02      0.46      0.06     -0.70      0.79    131.60      1.00\n",
      "  beta[13]     -0.00      0.14      0.01     -0.22      0.23    132.01      1.00\n",
      "  beta[14]     -0.01      0.23      0.01     -0.38      0.39    132.17      1.00\n",
      "     sigma      0.96      0.00      0.96      0.96      0.97   1377.26      1.00\n",
      "\n",
      "Number of divergences: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Run inference in Pyro\n",
    "nuts_kernel = NUTS(model)\n",
    "mcmc = MCMC(nuts_kernel, num_samples=1000, warmup_steps=200, num_chains=1)\n",
    "mcmc.run(X_train_small, y_train_small)\n",
    "\n",
    "# Show summary of inference results\n",
    "mcmc.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1152x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Extract samples from posterior\n",
    "posterior_samples = mcmc.get_samples()\n",
    "\n",
    "sns.distplot(posterior_samples[\"alpha\"])\n",
    "sns.distplot(posterior_samples[\"sigma\"])\n",
    "\n",
    "# Alternate plotting due to deprecated distplot-function\n",
    "#sns.histplot(data=posterior_samples[\"alpha\"], kde=True, stat='density', color=next(palette), element=\"step\")\n",
    "#sns.histplot(data=posterior_samples[\"sigma\"], kde=True, stat='density', color=next(palette), element=\"step\")\n",
    "\n",
    "plt.legend([\"alpha\", \"sigma\"])\n",
    "plt.axis([-10,10,0,5])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000])\n",
      "torch.Size([1000, 15])\n"
     ]
    }
   ],
   "source": [
    "print(posterior_samples[\"alpha\"].shape)\n",
    "print(posterior_samples[\"beta\"].shape)\n",
    "\n",
    "beta_hat=torch.mean(posterior_samples[\"beta\"], axis=0)\n",
    "alpha_hat=torch.mean(posterior_samples[\"alpha\"], axis=0)\n",
    "\n",
    "# Compute predictions\n",
    "y_hat = np.mean(posterior_samples[\"alpha\"].numpy().T + np.dot(X_test, posterior_samples[\"beta\"].numpy().T), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CorrCoef: 0.288\n",
      "MAE: 21.035\n",
      "RMSE: 36.341\n",
      "R2: 0.083\n"
     ]
    }
   ],
   "source": [
    "# Convert back to the original scale\n",
    "preds = y_hat * y_test_std + y_test_mean\n",
    "y_true = y_test * y_test_std + y_test_mean\n",
    "corr, mae, rae, rmse, r2 = compute_error(y_true, preds)\n",
    "print(\"CorrCoef: %.3f\\nMAE: %.3f\\nRMSE: %.3f\\nR2: %.3f\" % (corr, mae, rmse, r2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pyro: Train on full dataset using Stochastic Variational Inference (SVI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for Pyro model\n",
    "X_train_torch = torch.tensor(X_train).float()\n",
    "y_train_torch = torch.tensor(y_train).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define guide function\n",
    "guide = AutoMultivariateNormal(model)\n",
    "\n",
    "# Reset parameter values\n",
    "pyro.clear_param_store()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the number of optimization steps\n",
    "n_steps = 4000\n",
    "\n",
    "# Setup the optimizer\n",
    "adam_params = {\"lr\": 0.001} # learning rate (lr) of optimizer\n",
    "optimizer = ClippedAdam(adam_params)\n",
    "\n",
    "# Setup the inference algorithm\n",
    "elbo = Trace_ELBO(num_particles=1)\n",
    "svi = SVI(model, guide, optimizer, loss=elbo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] ELBO: 86305.1\n",
      "[100] ELBO: 76732.0\n",
      "[200] ELBO: 79898.0\n",
      "[300] ELBO: 74488.2\n",
      "[400] ELBO: 67177.9\n",
      "[500] ELBO: 66549.2\n",
      "[600] ELBO: 62835.6\n",
      "[700] ELBO: 63214.6\n",
      "[800] ELBO: 59650.1\n",
      "[900] ELBO: 57358.6\n",
      "[1000] ELBO: 56180.7\n",
      "[1100] ELBO: 52768.4\n",
      "[1200] ELBO: 53149.4\n",
      "[1300] ELBO: 51610.5\n",
      "[1400] ELBO: 51071.4\n",
      "[1500] ELBO: 50991.1\n",
      "[1600] ELBO: 50750.3\n",
      "[1700] ELBO: 50726.0\n",
      "[1800] ELBO: 50476.3\n",
      "[1900] ELBO: 50437.2\n",
      "[2000] ELBO: 50776.4\n",
      "[2100] ELBO: 50400.8\n",
      "[2200] ELBO: 50890.6\n",
      "[2300] ELBO: 50600.8\n",
      "[2400] ELBO: 50429.0\n",
      "[2500] ELBO: 50298.5\n",
      "[2600] ELBO: 50218.2\n",
      "[2700] ELBO: 50174.2\n",
      "[2800] ELBO: 50223.0\n",
      "[2900] ELBO: 50201.9\n",
      "[3000] ELBO: 50185.4\n",
      "[3100] ELBO: 50186.7\n",
      "[3200] ELBO: 50193.9\n",
      "[3300] ELBO: 50205.4\n",
      "[3400] ELBO: 50200.2\n",
      "[3500] ELBO: 50213.9\n",
      "[3600] ELBO: 50233.5\n",
      "[3700] ELBO: 50218.8\n",
      "[3800] ELBO: 50234.2\n",
      "[3900] ELBO: 50179.1\n"
     ]
    }
   ],
   "source": [
    "# Do gradient steps\n",
    "for step in range(n_steps):\n",
    "    elbo = svi.step(X_train_torch, y_train_torch)\n",
    "    if step % 100 == 0:\n",
    "        print(\"[%d] ELBO: %.1f\" % (step, elbo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyro.infer import Predictive\n",
    "\n",
    "predictive = Predictive(model, guide=guide, num_samples=1000,\n",
    "                        return_sites=(\"alpha\", \"beta\", \"sigma\"))\n",
    "samples = predictive(X_train_torch, y_train_torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CorrCoef: 0.287\n",
      "MAE: 21.040\n",
      "RMSE: 36.350\n",
      "R2: 0.082\n"
     ]
    }
   ],
   "source": [
    "alpha_samples = samples[\"alpha\"].detach().numpy()\n",
    "beta_samples = samples[\"beta\"].detach().numpy()\n",
    "y_hat = np.mean(alpha_samples.T + np.dot(X_test, beta_samples[:,0].T), axis=1)\n",
    "\n",
    "# Convert back to the original scale\n",
    "preds = y_hat * y_test_std + y_test_mean\n",
    "y_true = y_test * y_test_std + y_test_mean\n",
    "corr, mae, rae, rmse, r2 = compute_error(y_true, preds)\n",
    "print(\"CorrCoef: %.3f\\nMAE: %.3f\\nRMSE: %.3f\\nR2: %.3f\" % (corr, mae, rmse, r2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.3 Pyro: Heteroscedastic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def heteroscedastic_model(X, obs=None):\n",
    "    alpha_mu = pyro.sample(\"alpha_mu\", dist.Normal(0., 1.))                 # Prior for the bias/intercept of the mean\n",
    "    beta_mu  = pyro.sample(\"beta_mu\", dist.Normal(torch.zeros(X.shape[1]), \n",
    "                                               torch.ones(X.shape[1])).to_event())     # Priors for the regression coeffcients of the mean\n",
    "    alpha_v = pyro.sample(\"alpha_v\", dist.Normal(0., 1.))                   # Prior for the bias/intercept of the variance\n",
    "    beta_v  = pyro.sample(\"beta_v\", dist.Normal(torch.zeros(X.shape[1]), \n",
    "                                               torch.ones(X.shape[1])).to_event())     # Priors for the regression coeffcients of the variance\n",
    "    \n",
    "    with pyro.plate(\"data\"):\n",
    "        y = pyro.sample(\"y\", dist.Normal(alpha_mu + X.matmul(beta_mu), torch.exp(alpha_v + X.matmul(beta_v))), obs=obs)\n",
    "        \n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for Pyro model\n",
    "X_train_torch = torch.tensor(X_train).float()\n",
    "y_train_torch = torch.tensor(y_train).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] ELBO: 97512043.5\n",
      "[200] ELBO: 3020309.9\n",
      "[400] ELBO: 116975.6\n",
      "[600] ELBO: 70006.9\n",
      "[800] ELBO: 55430.0\n",
      "[1000] ELBO: 50924.9\n",
      "[1200] ELBO: 49800.2\n",
      "[1400] ELBO: 50331.6\n",
      "[1600] ELBO: 48725.2\n",
      "[1800] ELBO: 49302.9\n",
      "[2000] ELBO: 48187.6\n",
      "[2200] ELBO: 48813.5\n",
      "[2400] ELBO: 48057.3\n",
      "[2600] ELBO: 47839.2\n",
      "[2800] ELBO: 47807.4\n",
      "[3000] ELBO: 47632.9\n",
      "[3200] ELBO: 47711.6\n",
      "[3400] ELBO: 47645.5\n",
      "[3600] ELBO: 47347.1\n",
      "[3800] ELBO: 47409.3\n",
      "[4000] ELBO: 47324.5\n",
      "[4200] ELBO: 47420.4\n",
      "[4400] ELBO: 47300.1\n",
      "[4600] ELBO: 47341.3\n",
      "[4800] ELBO: 47343.3\n",
      "[5000] ELBO: 47325.4\n",
      "[5200] ELBO: 47268.7\n",
      "[5400] ELBO: 47300.8\n",
      "[5600] ELBO: 47264.7\n",
      "[5800] ELBO: 47254.8\n",
      "[6000] ELBO: 47287.5\n",
      "[6200] ELBO: 47277.6\n",
      "[6400] ELBO: 47261.8\n",
      "[6600] ELBO: 47254.3\n",
      "[6800] ELBO: 47255.4\n",
      "[7000] ELBO: 47250.8\n",
      "[7200] ELBO: 47265.5\n",
      "[7400] ELBO: 47269.0\n",
      "[7600] ELBO: 47243.3\n",
      "[7800] ELBO: 47256.8\n"
     ]
    }
   ],
   "source": [
    "# Define guide function\n",
    "guide = AutoMultivariateNormal(heteroscedastic_model)\n",
    "\n",
    "# Reset parameter values\n",
    "pyro.clear_param_store()\n",
    "\n",
    "# Define the number of optimization steps\n",
    "n_steps = 8000\n",
    "\n",
    "# Setup the optimizer\n",
    "adam_params = {\"lr\": 0.001} # learning rate (lr) of optimizer\n",
    "optimizer = ClippedAdam(adam_params)\n",
    "\n",
    "# Setup the inference algorithm\n",
    "elbo = Trace_ELBO(num_particles=1)\n",
    "svi = SVI(heteroscedastic_model, guide, optimizer, loss=elbo)\n",
    "\n",
    "# Do gradient steps\n",
    "for step in range(n_steps):\n",
    "    elbo = svi.step(X_train_torch, y_train_torch)\n",
    "    if step % 200 == 0:\n",
    "        print(\"[%d] ELBO: %.1f\" % (step, elbo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyro.infer import Predictive\n",
    "\n",
    "predictive = Predictive(heteroscedastic_model, guide=guide, num_samples=1000,\n",
    "                        return_sites=(\"alpha_mu\", \"beta_mu\", \"alpha_v\", \"beta_v\"))\n",
    "samples = predictive(X_train_torch, y_train_torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CorrCoef: 0.286\n",
      "MAE: 20.971\n",
      "RMSE: 36.477\n",
      "R2: 0.076\n"
     ]
    }
   ],
   "source": [
    "alpha_samples = samples[\"alpha_mu\"].detach().numpy()\n",
    "beta_samples = samples[\"beta_mu\"].detach().numpy()\n",
    "y_hat = np.mean(alpha_samples.T + np.dot(X_test, beta_samples[:,0].T), axis=1)\n",
    "\n",
    "# convert back to the original scale\n",
    "preds = y_hat * y_test_std + y_test_mean\n",
    "y_true = y_test * y_test_std + y_test_mean\n",
    "\n",
    "corr, mae, rae, rmse, r2 = compute_error(y_true, preds)\n",
    "print(\"CorrCoef: %.3f\\nMAE: %.3f\\nRMSE: %.3f\\nR2: %.3f\" % (corr, mae, rmse, r2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_v_samples = samples[\"alpha_v\"].detach().numpy()\n",
    "beta_v_samples = samples[\"beta_v\"].detach().numpy()\n",
    "sigma_hat = np.mean(np.exp(alpha_v_samples.T + np.dot(X_test, beta_v_samples[:,0].T)), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.743 0.54  0.925 0.619 0.889 0.594 0.825 1.213 0.763 0.946]\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(precision=3)\n",
    "print(sigma_hat[:10])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f3449860fed0861a1e81fd060afa67eac864f2ca12d1913a45e827e462276ab2"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('ModelML')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
