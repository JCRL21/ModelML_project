{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jcrl\\miniconda3\\envs\\ModelML\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd   \n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import itertools\n",
    "\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "from pyro.contrib.autoguide import AutoDiagonalNormal, AutoMultivariateNormal\n",
    "from pyro.infer import MCMC, NUTS, HMC, SVI, Trace_ELBO\n",
    "from pyro.optim import Adam, ClippedAdam\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "# fix random generator seed (for reproducibility of results)\n",
    "np.random.seed(42)\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "# matplotlib options\n",
    "palette = itertools.cycle(sns.color_palette())\n",
    "plt.style.use('ggplot')\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (16, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Data/data_pre.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop([\"Unnamed: 0\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"DEP_TIME\"] = pd.to_datetime(df[\"DEP_TIME\"]).dt.hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"FL_DATE\"]=pd.to_datetime(df[\"FL_DATE\"]).dt.dayofyear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(54180, 15)\n"
     ]
    }
   ],
   "source": [
    "X = df.drop([\"DEP_DELAY\"], axis=1)\n",
    "print(X.shape)\n",
    "X = X.to_numpy()\n",
    "\n",
    "\n",
    "y = df[\"DEP_DELAY\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "# standardize input features\n",
    "X_train_mean = X_train.mean(axis=0)\n",
    "X_train_std = X_train.std(axis=0)\n",
    "X_train = (X_train - X_train_mean) / X_train_std\n",
    "\n",
    "X_test_mean = X_test.mean(axis=0)\n",
    "X_test_std = X_test.std(axis=0)\n",
    "X_test = (X_test - X_test_mean) / X_test_std\n",
    "\n",
    "# standardize target\n",
    "y_train_mean = y_train.mean()\n",
    "y_train_std = y_train.std()\n",
    "y_train = (y_train - y_train_mean) / y_train_std\n",
    "\n",
    "y_test_mean = y_test.mean()\n",
    "y_test_std = y_test.std()\n",
    "y_test = (y_test - y_test_mean) / y_test_std\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_error(trues, predicted):\n",
    "    corr = np.corrcoef(predicted, trues)[0,1]\n",
    "    mae = np.mean(np.abs(predicted - trues))\n",
    "    rae = np.sum(np.abs(predicted - trues)) / np.sum(np.abs(trues - np.mean(trues)))\n",
    "    rmse = np.sqrt(np.mean((predicted - trues)**2))\n",
    "    r2 = max(0, 1 - np.sum((trues-predicted)**2) / np.sum((trues - np.mean(trues))**2))\n",
    "    return corr, mae, rae, rmse, r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CorrCoef: -0.011\n",
      "MAE: 3533056383.960\n",
      "RMSE: 5206834839.693\n",
      "R2: 0.000\n"
     ]
    }
   ],
   "source": [
    "regr = linear_model.LinearRegression()\n",
    "regr.fit(X_train, y_train)\n",
    "y_hat = regr.predict(X_test)\n",
    "\n",
    "# Convert back to the original scale\n",
    "preds = y_hat * y_test_std + y_test_mean\n",
    "y_true = y_test * y_test_std + y_test_mean\n",
    "\n",
    "\n",
    "corr, mae, rae, rmse, r2 = compute_error(y_test, y_hat)\n",
    "print(\"CorrCoef: %.3f\\nMAE: %.3f\\nRMSE: %.3f\\nR2: %.3f\" % (corr, mae, rmse, r2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(X, obs=None):\n",
    "    \n",
    "    alpha = pyro.sample(\"alpha\", dist.Normal(0., 1.))                   # Prior for the bias/intercept\n",
    "    beta  = pyro.sample(\"beta\", dist.Normal(torch.zeros(X.shape[1]), \n",
    "                                            torch.ones(X.shape[1])).to_event())    # Priors for the regression coeffcients\n",
    "    sigma = pyro.sample(\"sigma\", dist.HalfCauchy(5.))                   # Prior for the variance\n",
    "    with pyro.plate(\"data\"):\n",
    "        y = pyro.sample(\"y\", dist.Normal(alpha + X.matmul(beta), sigma), obs=obs)\n",
    "        \n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for Pyro model\n",
    "X_train_small = torch.tensor(X_train).float()\n",
    "y_train_small = torch.tensor(y_train).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sample: 100%|██████████| 1200/1200 [06:51,  2.92it/s, step size=2.43e-02, acc. prob=0.914]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                mean       std    median      5.0%     95.0%     n_eff     r_hat\n",
      "     alpha     -0.00      0.01     -0.00     -0.01      0.01    880.22      1.00\n",
      "   beta[0]     -0.00      0.02     -0.00     -0.04      0.03    385.23      1.00\n",
      "   beta[1]      0.23      0.01      0.23      0.22      0.24    891.87      1.00\n",
      "   beta[2]      0.12      0.01      0.12      0.11      0.12    973.74      1.00\n",
      "   beta[3]     -0.04      0.02     -0.04     -0.08     -0.01    399.30      1.00\n",
      "   beta[4]     -0.14      0.01     -0.14     -0.15     -0.13    708.99      1.00\n",
      "   beta[5]      0.03      0.32      0.04     -0.42      0.57     87.19      1.03\n",
      "   beta[6]     -0.04      0.41     -0.03     -0.61      0.65     87.03      1.03\n",
      "   beta[7]     -0.01      0.07     -0.01     -0.11      0.11     86.39      1.04\n",
      "   beta[8]     -0.03      0.28     -0.03     -0.42      0.44     87.12      1.03\n",
      "   beta[9]     -0.00      0.09      0.00     -0.12      0.14     87.08      1.03\n",
      "  beta[10]     -0.03      0.52     -0.02     -0.76      0.86     87.01      1.03\n",
      "  beta[11]      0.00      0.07      0.01     -0.10      0.12     88.21      1.03\n",
      "  beta[12]     -0.01      0.41     -0.00     -0.59      0.69     87.10      1.03\n",
      "  beta[13]     -0.01      0.12     -0.01     -0.18      0.19     86.99      1.03\n",
      "  beta[14]     -0.03      0.21     -0.02     -0.32      0.33     87.19      1.03\n",
      "     sigma      0.96      0.00      0.96      0.96      0.97   1222.34      1.00\n",
      "\n",
      "Number of divergences: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Run inference in Pyro\n",
    "nuts_kernel = NUTS(model)\n",
    "mcmc = MCMC(nuts_kernel, num_samples=1000, warmup_steps=200, num_chains=1)\n",
    "mcmc.run(X_train_small, y_train_small)\n",
    "\n",
    "# Show summary of inference results\n",
    "mcmc.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA7QAAAJDCAYAAAA7J1i7AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAoGklEQVR4nO3de7zlZUHv8e8eBmYm7rhLHKOj4QWRE1ooVh6BVEQlPWrnCTsSqYH6ioqKk5dTal4yLxS+1JNSzksyw54oTQq8cAZvp7SEtFApUUxuaoDCcBl0Ztb5Y62ZNsOemb2We6/f79n7/X699st1m/17xoe113z287vMDAaDAAAAQGtWdT0AAAAAmISgBQAAoEmCFgAAgCYJWgAAAJokaAEAAGiSoAUAAKBJq6e1oVLKV5NsSrI1yZZa6zHT2jYAAADLz9SCduSEWutNU94mAAAAy5BdjgEAAGjSNIN2kOTDpZTLSylnTHG7AAAALEPT3OX4sbXW60spP5DkI6WUq2qtH5/7glHonpEktdYfm+LYAAAAmK6Z7/kbDAaDxRjIWEopr0xye631Tbt52eCGG26Y0ohYTLOzs7npJodKt8r8tcvctWlwxd9n2x++Lkmy6ldekZn/2t/f537+G3fmZZd+LUly4SkPzd57fc//Dlk2vP/aZe7aZv7atX79+mQRgnYquxyXUvYtpey//XaSE5NcOY1tAwAAsDxNa5fj+yZ5Xyll+zb/rNb6wSltGwAAgGVoKkFba/1KkqOnsS0AAABWhmlfhxYAAGBFGAwG2bx5c7Zt25aZmZV33oHBYJBVq1Zl7dq1S/b3F7QAAABLYPPmzdl7772zevXKza4tW7Zk8+bNWbdu3ZJ8/2lehxYAAGDF2LZt24qO2SRZvXp1tm3btmTfX9ACAAAsgZW4m/F8lvL/B0ELAL0x/WvDA7AyHXvssbnlllu+59d0TdACQKdELABMStACAAAsY8973vNy0kkn5YQTTsif/umf3uO5a6+9No973ONy5pln5rjjjsvpp5+eu+66a8fzGzZsyJOe9KQ8/vGPz9VXX50k+ad/+qf89E//dE488cQ87WlP2/F4FwQtAADAMnbOOefkgx/8YC6++OJs2LDhXrsRf/nLX85pp52Wj33sY9l///1z/vnn73jukEMOyYc+9KGceuqpefvb354kedCDHpT3ve99+fCHP5yzzz47r3/966f695lrZZ9yCwAAYAq2vfePMrj2mkX9njOHPTCrTjl9j6/bsGFDLrnkkiTJDTfckGuuuec41q9fn0c96lFJkmc+85nZsGFDXvjCFyZJnvzkJydJfuRHfmTH97jtttty1lln5ZprrsnMzEy++93vLtrfaVxWaAEAAJapv/u7v8snPvGJXHTRRbn00ktz1FFH5e67777Ha3Y+C/Hc+2vWrEmS7LXXXtm6dWuS5I1vfGN+4id+Ihs3bsy73vWue32/abJCCwBMYJDE5SgAFmohK6lLYdOmTTnwwAOzbt26XH311bniiivu9Zrrr78+n/nMZ3LMMcfk/e9//47V2t19z0MPPTRJUmtdknEvlBVaAACAZer444/P1q1bc9xxx+V3f/d386M/+qP3es3hhx+e888/P8cdd1xuvfXWnHbaabv9ni960Yvyute9LieeeGK2bNmyVENfECu0AAAAy9SaNWvudWbjJPn0pz+dJLnjjjuyevXqvOUtb9nla5Lk6KOPzoUXXpgkOeaYY/LJT35yx3MvfvGLF3vYC2aFFgAAgCYJWgDo0mDu7cEuXwYAS+Gwww7Lxo0bux7GxAQtAAAATRK0AAAANEnQAgALYodoAPpG0AIAANAkQQsAALCCnH322fm3f/u3roexKFyHFgAAYAV505ve1PUQFo2gBQAAWKbuvPPOvOAFL8iNN96Ybdu25Vd/9Vfz7ne/O7/927+do48+OhdccEHe9ra35cADD8yRRx6ZffbZJ6997Wtz1llnZe3atbnyyitz880355xzzsmFF16Yyy+/PI985CNz7rnnJkle8pKX5HOf+1w2b96cpz71qTn77LOn+vezyzEAAMAyddlll+XQQw/NpZdemo0bN+aEE07Y8dzXv/71nHvuubnooovy/ve/P1dfffU9/uytt96aiy66KK985Svz3Oc+N6effnouu+yyXHXVVbnyyiuTJC9+8YtzySWX5NJLL82nPvWpfOELX5jq388KLQB0ajDvTQCWlz/+zDdyzbc2L+r3fODBa/OLx9x3t6854ogj8qpXvSqvfe1r84QnPCHHHnvsjuc++9nP5jGPeUwOPvjgJMnJJ5+cr3zlKzuef+ITn5iZmZkcccQRmZ2dzcMe9rAkyUMe8pBcd911Oeqoo3LRRRflPe95T7Zu3ZpvfOMb+dKXvpQjjzxyUf+euyNoAQAAlqnDDz88H/zgB7Nx48a84Q1vyGMf+9gF/9l99tknSbJq1aqsWbNmx+OrVq3Kli1b8rWvfS3veMc78rd/+7c56KCDctZZZ2Xz5sWN9j0RtAAAAEtsTyupS+XrX/96DjrooDzrWc/KAQcckAsuuGDHc0cffXRe8YpX5Nvf/nb222+/XHzxxTniiCMW/L03bdqUdevW5YADDsh//Md/5LLLLsuP//iPL8VfY5cELQAwNntHA7Thqquuymte85rMzMxk7733zute97q8+tWvTpLc7373yy//8i/nqU99ag4++OAcfvjh2X///Rf8vR/+8IfnqKOOyuMe97isX78+j3rUo5bqr7FLghYAAGCZOv7443P88cff47ELL7xwx+1nPOMZec5znpMtW7bk+c9/fk466aQk2XEW4yQ57LDDsnHjxh335z4393YXBC0AAMAKdc455+QTn/hE7r777hx33HE7grYVghYAAGCFevnLX971EL4nrkMLAABAkwQtAHRp4PRKAMvVwM/4JEv7/4OgBQAAWALbr9e6km3ZsiWrVi1ddjqGFgB6w2/yAZaTtWvXZvPmzbn77rszMzPT9XCmbjAYZNWqVVm7du2SbUPQAgAALIGZmZmsW7eu62Esa3Y5BgAAoEmCFgAAgCYJWgAAAJokaAEAAGiSoAUAAKBJghYAOrSE15pfdAOXFQKgZwQtAAAATRK0AMDYWlpZBmD5ErQA0BcqEQDGImgBAABokqAFAACgSYIWAACAJglaAAAAmiRoAaBTTgQFAJMStAAAADRJ0AIAANAkQQsAAECTBC0A9IbjaQFgHIIWAACAJglaAAAAmiRoAQAAaJKgBQAAoEmCFgC6NHAiKACYlKAFAACgSYIWAACAJglaAAAAmiRoAQAAaJKgBYC+6Pn5oZy/CoC+EbQAAAA0SdACAADQJEELAABAkwQtAHTJgakAMDFBCwAAQJMELQAAAE0StAAAADRJ0AIAANAkQQsAfeEEUQAwFkELAABAkwQtAAAATRK0AMDY7BwNQB8IWgAAAJokaAEAAGiSoAUAAKBJghYAAIAmCVoAAACaJGgBAABokqAFgN5wMRwAGIegBQAAoEmCFgC6NLAqCwCTErQAAAA0SdACAADQJEELAABAkwQtAAAATRK0AAAANEnQAgAA0CRBCwCMzdWGAOgDQQsAnRrMexMA2DNBCwAAQJMELQAAAE0StAAAADRJ0AIAANAkQQsAAECTBC0AAABNErQAAAA0SdACAADQpNXT3FgpZa8kn0lyfa315GluGwB6abDLOwDAHkx7hfZXk3xxytsEAABgGZpa0JZSfjDJU5P88bS2CQAAwPI1zRXac5P8ZpJtU9wmAAAAy9RUjqEtpZyc5Ju11stLKcfv5nVnJDkjSWqtmZ2dncbwWGSrV682dw0zf+0yd226a//9ctvo9v7775+1PZ7DA+9aneTaJMl97nOffN8+e3U7oB7x/muXuWub+WNaJ4X6ySRPK6U8JcnaJAeUUv601vqcuS+qtZ6X5LzR3cFNN900peGxmGZnZ2Pu2mX+2mXu2rRt0+07bm/atCm393gOb731jh23b7755ty5t4slbOf91y5z1zbz167169cvyveZStDWWl+a5KVJMlqhPXvnmAUA2jFwRmYAesCvVgEAAGjSVK9DmyS11o8m+ei0twsAfG+syQLQN1ZoAaBLA5kIAJMStADQF+IWAMYiaAEAAGiSoAUAAKBJghYAAIAmCVoAAACaJGgBAABokqAFAACgSYIWADrlUj0AMClBCwAAQJMELQD0xMBiLQCMRdACAADQJEELAABAkwQtAAAATRK0AAAANEnQAgAA0CRBCwAAQJMELQB0yaV6AGBighYAAIAmCVoAAACaJGgBoDfsfwwA4xC0AMCCDPQ2AD0jaAEAAGiSoAUAAKBJghYAAIAmCVoAAACaJGgBoFPOtAQAkxK0AAAANEnQAgAA0CRBCwCMzTVpAegDQQsAfaESAWAsghYAAIAmCVoAAACaJGgBAABokqAFgC45bhYAJiZoAQAAaJKgBQAAoEmCFgAAgCYJWgAAAJokaAGgL5wgCgDGImgBAABokqAFAACgSYIWAACAJglaAOiS42YBYGKCFgAAgCYJWgBgbNaVAegDQQsAAECTBC0AAABNErQAAAA0SdACAADQJEELAABAkwQtAAAATRK0AAAANEnQAgAA0CRBCwAAQJMELQAAAE0StADAggy6HgAA7ETQAgAA0CRBCwB9MbAGCgDjELQAAAA0SdACQJesygLAxAQtADA+HQ5ADwhaAAAAmiRoAQAAaJKgBQAAoEmCFgAAgCYJWgAAAJokaAEAAGiSoAWA3nAtHAAYh6AFgE6JWACYlKAFAACgSYIWAACAJglaAAAAmiRoAYAFGQwc7wtAvwhaAAAAmiRoAQAAaJKgBQAAoEmCFgC61OhhqY0OG4BlRtACQF+oRAAYi6AFAACgSYIWAACAJglaAAAAmiRoAQAAaJKgBQAAoEmCFgAAgCYJWgAAAJokaAGgSwMXnwWASQlaAOgLcQsAYxG0AAAANEnQAgAA0CRBCwAAQJMELQAAAE0StAAAADRJ0AIAY3M+ZgD6QNACAADQJEELAJ2y1gkAkxK0AAAANEnQAkBvWK0FgHEIWgAAAJokaAEAAGjS6mlspJSyNsnHk6wZbfPCWusrprFtAAAAlqdprdDeneSnaq1HJ3lEkpNKKY+Z0rYBAABYhqayQltrHSS5fXR379GXM18AAAAwsakEbZKUUvZKcnmSByV5W63109PaNgD0ll/vAsDEpha0tdatSR5RSjkoyftKKUfVWq+c+5pSyhlJzhi9PrOzs9MaHoto9erV5q5h5q9d5q5Nd+63bzaNbu+/3/5Z1+M5POD2vZJclyS5zyGH5MB1e3c7oB7x/muXuWub+WNqQbtdrfXbpZTLkpyU5MqdnjsvyXmju4Obbrpp2sNjEczOzsbctcv8tcvctWnb7XfsuL3p9k25o8dzeNttt++4ffMtt+S7a/bqcDT94v3XLnPXNvPXrvXr1y/K95nKSaFKKd8/WplNKWVdkicmuWoa2waAZtj9GADGMq0V2vslOX90HO2qJLXW+jdT2jYAAADL0LTOcvzPSR45jW0BAEtjYAUZgJ6Z1nVoAYDlRN0C0AOCFgAAgCYJWgAAAJokaAGgU3bdBYBJCVoAAACaJGgBAABokqAFAACgSYIWAHrD8bQAMA5BCwAAQJMELQAAAE0StAAAADRJ0AJAlwaOmwWASQlaAAAAmiRoAQAAaJKgBQAAoEmCFgAAgCYJWgBgQQa7uA0AXRG0ANAXzngMAGMRtAAAADRJ0AIAANAkQQsAXbKXMQBMTNACAADQJEELAABAkwQtAAAATRK0AAAANEnQAgAA0CRBCwB9MXDKYwAYh6AFAACgSYIWAACAJi04aEspTy+lrF7KwQDAymM3YwCY1DgrtK9KcmMp5a2llGOXakAAAACwEAsO2lrr0UmekOSuJH9ZSvnXUspvlVIesFSDAwAAgF0ZaxfiWuvnknyulPKbSR6f5Jwkv1NK+X9J3pHkglrrtsUfJgDQJ3aUBqAPxj4mtpRyeJLnjL62JXl5kq8lOTPJs5I8czEHCAAAAPNZcNCWUn4pyalJHpzkz5OcWmv91Jzn/zLJNxd9hAAAADCPcVZon5zhLsYfqLXevfOTtdY7SylWZwEAAJiKcc5y/NFa61/sHLOllF/ffrvW+uFFGxkAAADsxjhB+/JdPP5bizEQAFiRBk6vBACT2uMux6WUn9r+2lLKCUlm5jz9w0k2LcXAAAAAYHcWcgztO0f/uybJhjmPD5J8PckvL/agAAAAYE/2GLS11gcmSSnlT2qtP7/0QwIAAIA9W/AxtGIWAACAPtntCm0p5Yu11oeNbl+b4W7G91Jr/aElGBsAAADs0p52OT59zu3nLOVAAAAAYBy7Ddpa6yfn3P7Y0g8HAAAAFmYhZzlOkpRSfj3JxlrrZ0spj0lSk2xN8nO11r9fqgECwIrhmrQAMJYFnxQqya8luWZ0+3VJfj/Ja5Kcu8hjAoAVRMQCwKTGCdoDa623llL2T3J0krfUWt+Z5KFLMzQAAADYtQXvcpzk2lLKTyR5eJKP11q3llIOyHC3YwBgJbGwDEAPjBO0/yvJhUm+k+RZo8dOTvIPiz0oAAAA2JMFB22t9eIk63d6+C9GXwAAADBV46zQppRyYIbHzO6301MbF21EAEAvOQkzAH0zzmV7fiHJ25LcnuTOOU8Nkvzw4g4LAAAAdm+cFdrXJvmZWuslSzUYAAAAWKhxLtuzOsmHl2ogALAi2Y0XACY2TtC+PslvlVLG+TMAwIKpWwAYxzi7HP9akkOT/GYp5ea5T9Raf2hRRwUAAAB7ME7QPmfJRgEAAABjGuc6tB9byoEAAADAOMa5bM+aJC9P8uwk96m1HlhKOTHJQ2qtb12qAQIAAMB8xjnB0x8kOSrJ/8x/nrXi80letNiDAgAAgD0ZJ2ifkeTnaq1/n2RbktRar09y/6UYGAAAAOzOOEH7ney0i3Ip5fuT3Dz/ywEAAGDpjBO0f5Hk/FLKA5OklHK/JG9N8t6lGBgArAgD154FgEmNE7QvS/KVJP+S5KAkX0pyY5LfWfxhAQB9JsMB6INxrkP7oCT/muR3k+yV5P211n9ZklEBwEqkEgFgLHsM2lLKTJJ3JjktyXVJbsjwRFCvKKW8O8nzaq0+ggEAAJiqhazQnpHk+CSPqbX+4/YHSymPSnJBkhckefuSjA4AAAB2YSHH0J6a5FfmxmySjO6fNXoeAAAApmohQXtkko/t4rmPjZ4HAJa5gYN8AeiZhQTtXrXWTfM9MXp8nDMlAwAAwKJYyDG0e5dSTkgy8z18DwAAAFhUC4nRbybZsIfnAYCJ2I0XACa1x6CttT5gCuMAAACAsTj+FQD6YmC1FgDGIWgBAABokqAFAACgSYIWAACAJglaAAAAmiRoAQAAaJKgBYAuNXpi40aHDcAyI2gBAABokqAFAACgSYIWAACAJglaAOgNR6YCwDgELQAAAE0StADAglg/BqBvBC0AAABNErQAAAA0SdACQKfsyAsAkxK0AAAANEnQAgAA0CRBCwAAQJMELQD0hcNpAWAsghYAAIAmCVoAAACaJGgBgLENBvaPBqB7ghYAAIAmCVoA6JKVTgCY2OppbKSUcliSP0ly3wzP4XherfXN09g2AAAAy9O0Vmi3JPmNWuuRSR6T5JdKKUdOadsAAAAsQ1MJ2lrrjbXWK0a3NyX5YpL7T2PbAAAALE9TP4a2lPKAJI9M8ulpbxsAAIDlYyrH0G5XStkvyV8mOavWets8z5+R5IwkqbVmdnZ2msNjkaxevdrcNcz8tcvctemOfffN7aPb++27b76vx3N4wK0zSa5PkhxyyCGZ3W9NtwPqEe+/dpm7tpk/pha0pZS9M4zZ99Ra/2q+19Raz0ty3uju4KabbprW8FhEs7OzMXftMn/tMndt2nbHHTtu337H7bmzx3N4222bdty+5ZZbMrN57w5H0y/ef+0yd20zf+1av379onyfqexyXEqZSfLOJF+stf7+NLYJAADA8jatFdqfTHJqkn8ppXx29NjLaq0XT2n7ANBPLkMLABObStDWWj+ZZGYa2wIAAGBlmPpZjgEAAGAxCFoAAACaJGgBAABokqAFAACgSYIWAACAJglaAOiLgWv4AMA4BC0AAABNErQA0CmrsgAwKUELAABAkwQtAAAATRK0AAAANEnQAgAA0CRBCwAAQJMELQCwIM7HDEDfCFoA6AvFCABjEbQA0KWBigWASQlaAAAAmiRoAQAAaJKgBQAAoEmCFgAAgCYJWgBgbE5lBUAfCFoAAACaJGgBAABokqAFAACgSYIWALo0mHs0qiNTAWAcghYAAIAmCVoAAACaJGgBAABokqAFAACgSYIWAACAJglaAGBBnIMZgL4RtAAAADRJ0AIAANAkQQsAfTGwUy8AjEPQAgAA0CRBCwAAQJMELQAwNntHA9AHghYAAIAmCVoAAACaJGgBAABokqAFAACgSYIWALrk7EoAMDFBCwAAQJMELQD0htVaABiHoAUAAKBJghYAAIAmCVoAAACaJGgBgIVxiC8APSNoAQAAaJKgBQAAoEmCFgA6ZT9eAJiUoAUAAKBJghYAAIAmCVoA6At7HwPAWAQtAAAATRK0AAAANEnQAgAA0CRBCwAAQJMELQAAAE0StADQJWc2BoCJCVoAAACaJGgBAABokqAFgL4Y2P8YAMYhaAEAAGiSoAUAAKBJghYAWJCBUzID0DOCFgAAgCYJWgDokhNBAcDEBC0AMDYdDkAfCFoAAACaJGgBAABokqAFAACgSYIWAHrDgakAMA5BCwAAQJMELQAAAE0StAAAADRJ0AJApxw3CwCTErQAAAA0SdACAADQJEELAABAkwQtAAAATRK0ANAXzg8FAGMRtADAguhtAPpG0AIAANAkQQsAXWp02XPQ6sABWFYELQAAAE0StAAAADRJ0AIAANAkQQsAAECTBC0AAABNErQAAAA0SdACQG+4FA4AjEPQAgAA0CRBCwCdsioLAJMStAAAADRJ0AIAANAkQQsAAECTBC0AAABNErQAAAA0SdACAAvjhMwA9MzqaWyklLIhyclJvllrPWoa2wQAAGB5m9YK7buSnDSlbQFAmwaWQAFgHFMJ2lrrx5PcMo1tAUBTRCwATMwxtAAAADRpKsfQLlQp5YwkZyRJrTWzs7Mdj4hJrF692tw1zPy1y9y16fZ163LH6Pa+++6bfXs8h/t/K0luSJIcfPAhmT1wbafj6RPvv3aZu7aZP3oVtLXW85KcN7o7uOmmm7ocDhOanZ2NuWuX+WuXuWvTtjvv2nH7jjvuyF09nsNNt9224/a3vnVL9vnuPh2Opl+8/9pl7tpm/tq1fv36Rfk+djkGAACgSVMJ2lLKBUn+PslDSynXlVKeP43tAkD/OSkUAExqKrsc11qfPY3tAAAAsHLY5RgAuuSyPQAwMUELAH2hbQFgLIIWADqlYgFgUoIWAACAJglaAOgNq7UAMA5BCwBd0rAAMDFBCwB94YzHADAWQQsAXWo0YhsdNgDLjKAFgL7oeSX2e3QArESCFgC6NjPT9QgAoEmCFgA6Zd0TACYlaAGABen5HtEArECCFgC6NEgSuxwDwCQELQB0bXvPWgIFgLEIWgAAAJokaAGgU4PMWaLtciB71O/RAbASCVoA6JpDaAFgIoIWALrkuFkAmJigBYDOjZZotS0AjEXQAgAA0CRBCwBdusc5oSzRAsA4BC0AdM5ZoQBgEoIWADo1mNOz/V6hHVhBBqBnBC0AdK69FVppC0AfCFoA6NLcVU+VCABjEbQAwILobQD6RtACAADQJEELAL1hDRQAxiFoAaBrM+2dFAoA+kDQAkCX7nFSKCu0ADAOQQsAfWCVFgDGJmgBoC8s0ALAWAQtAHSpod2MGxoqACuEoAUAAKBJghYAOjXYxW0AYE8ELQB0bWbGSaEAYAKCFgD6oucHqfZ7dACsRIIWALqkEgFgYoIWAHpD3QLAOAQtAHRqe8Q6hhYAxiVoAaBzYhYAJiFoAaAv7HEMAGMRtADQpe1nNrZICwBjE7QA0LXtMdv3y/b0fHwArDyCFgC6tKMRLdECwLgELQD0hhVQABiHoAWATrVzDK3cBqBvBC0AdG2mgZoFgB4StADQF5ZAAWAsghYAurTjzMFWaQFgXIIWAHrDEi0AjEPQAgAA0CRBCwCdG+1uPLBCCwDjELQA0AcNHEKrtwHoG0ELAF1SiQAwMUELAF3bvjrbUNvqcAD6QNACQJdctgcAJiZoAaA3+r3s2e/RAbASCVoA6AMLtAAwNkELAJ2as+7pwFQAGIugBYDOzcQSLQCMT9ACQJcsygLAxAQtAHTN4iwATETQAgAA0CRBCwBdGrRzUqieDw+AFUjQAkDnZpIZ+x0DwLgELQB0qp0VWgDoG0ELAABAkwQtALAgA9cYAqBnBC0AdGmwyzsAwB4IWgDo2sxMZpwUCgDGJmgBoFODeW/20aCdoQKwQghaAOiSMxsDwMQELQB0aZBkZu4dAGChBC0AdGp70TqGFgDGJWgBAABokqAFgC7d40xLdjkGgHEIWgDo2syMPY4BYAKCFgC61NC1cHo+PABWIEELAF3aEbSWaAFgXIIWADo0yGC4y/HoHgCwcIIWALpkgRYAJiZoAaBzbdSskzAD0DeCFgA65bI9ADApQQsAXRoMWlmgBYDeEbQA0CWLsgAwMUELAJ0aneV4xjItAIxL0AJAlwZtHkM7sLQMQA8IWgDonNVZAJiEoAWArjXSs1ZlAegbQQsAXWp0l2MA6ANBCwBdGgwyXKJtZJkWAHpE0AJAb/R7hdYCMgB9I2gBoEuDgQVaAJiQoAWATm3f5Th9X6AFgN4RtADQpR378VqiBYBxCVoA6NqMmAWASQhaAOjS3N2Me37WpW39Hh4AK5CgBYBOjSrRIi0AjE3QAkCXtp/leHiny5Hs0baeryADsPKsntaGSiknJXlzkr2S/HGt9femtW0A6Lc2rtsjZwHom6ms0JZS9krytiRPTnJkkmeXUo6cxrYBoNe2bk1mRh/HfS/Gvo8PgBVnWrscPzrJ1bXWr9Rav5PkvUmePqVtA0B/bduarOr/6mySbOt6AACwk2kF7f2TXDvn/nWjxwBgZZu7QtvzJdDto/yBfffOapcaAqAHpnYM7UKUUs5IckaS1Fqzfv36jkfEpMxd28xfu8xdg976Z12PYMHOXL8+Zz6x61H0l/dfu8xd28zfyjatFdrrkxw25/4Pjh67h1rrebXWY2qtx5RSLs9/niXDV0Nf5q7tL/PX7pe5a/vL/LX9Zf7a/TJ3bX+Zv3a/RnP3PZvWCu0/JnlwKeWBGYbsKUl+bkrbBgAAYBmaygptrXVLkjOTfCjJF4cP1c9PY9sAAAAsT1M7hrbWenGSi8f4I+ct1VhYcuaubeavXeaubeavbeavXeaubeavXYsydzODQb/PqAgAAADzmdZJoQAAAGBRdXbZnlLK/0jyyiQPS/LoWutn5jz30iTPT7I1ya/UWj80z59/YJL3JrlPksuTnFpr/c4Uhs5OSil/nuSho7sHJfl2rfUR87zuq0k2ZTivW2qtx0xpiOxGKeWVSU5P8h+jh142OkRg59edlOTNSfZK8se11t+b2iCZVynljUl+Osl3knw5yXNrrd+e53Vfjfdeb+zpvVRKWZPkT5L8WJKbk/xsrfWr0x4n91RKOSzDeblvhhcMPq/W+uadXnN8kr9Ocs3oob+qtb5qmuNk1/b0s7CUMpPhe/MpSe5M8gu11iumPU7urZTy0CR/PuehH07y8lrruXNec3y8/3qhlLIhyclJvllrPWr02CEZzuEDknw1Sam1fmueP3takt8a3X1NrfX8PW2vy+vQXpnkmUneMffBUsqRGZ4F+eFJ1ie5tJTykFrr1p3+/OuT/EGt9b2llLdnGMB/uPTDZme11p/dfruUck6SW3fz8hNqrTct/agY0x/UWt+0qydLKXsleVuSJya5Lsk/llI+UGv9wrQGyLw+kuSltdYtpZTXJ3lpkhfv4rXeez2wwPfS85N8q9b6oFLKKRl+3v3svb8bU7YlyW/UWq8opeyf5PJSykfm+Tn4iVrryR2Mj4XZ3c/CJyd58Ojr2Az/XXnstAbGrtVa/zXJI5IdP0evT/K+eV7q/dcP70ry1gx/CbjdS5L831rr75VSXjK6f49/s4yi9xVJjsnwF4eXjz4j7xW+c3W2y3Gt9Yuj/zh39vQk76213l1rvSbJ1UkePfcFo9+g/VSSC0cPnZ/kvy/hcFmA0byUJBd0PRYW3aOTXF1r/cpoT4j3ZvhepUO11g+PziKfJJ/K8Brf9NtC3ktPz/BzLRl+zj1+9POVDtVab9y+Wldr3ZThVRvu3+2oWGRPT/IntdZBrfVTSQ4qpdyv60FxL49P8uVa6793PRDmV2v9eJJbdnp47mfbrtrtSUk+Umu9ZRSxH0ly0p6218djaO+f5No596/LvT8w7pPhbq1bdvMapu+/JflGrfVLu3h+kOTDpZTLSylnTHFc7NmZpZR/LqVsKKUcPM/zC3lf0q3nJblkF8957/XHQt5LO14z+py7NcPPPXqilPKAJI9M8ul5nv7xUsrnSimXlFIePt2RsQd7+lnos64Np2TXiyfef/1131rrjaPbX8/w8I2dTfQeXNJdjksplyY5dJ6n/net9a+XctssrgXO5bOz+9XZx9Zary+l/ECSj5RSrhr9Bocltrv5y3CXqldn+EH/6iTnZBhH9MBC3nullP+d4e6Q79nFt/Heg0VSStkvyV8mOavWettOT1+R5L/UWm8vpTwlyfsz3H2VfvCzsHGllH2SPC3DQ2x25v3XiFrroJSyaJfaWdKgrbU+YYI/dn2Sw+bc/8HRY3PdnOFuIKtHv72e7zUsoj3NZSlldYbHRP/Ybr7H9aP//WYp5X0Z7nrng2QKFvpeLKX8UZK/meephbwvWQILeO/9QoYnXnh8rXXeDwfvvV5ZyHtp+2uuG/1sPTDDzz06VkrZO8OYfU+t9a92fn5u4NZaLy6l/J9Syqzj1/thAT8Lfdb135OTXFFr/cbOT3j/9d43Sin3q7XeONqV/5vzvOb6JMfPuf+DST66p2/cx12OP5DklFLKmtGZjB+c5B/mvmD0j7bLkvzM6KHTMjyrGd15QpKraq3XzfdkKWXf0Uk0UkrZN8mJGZ4YjI7tdHzQMzL/vPxjkgeXUh44+u3oKRm+V+nQ6Gy5v5nkabXWO3fxGu+9flnIe+kDGX6uJcPPuY27+mUF0zM6jvmdSb5Ya/39Xbzm0O3HO5dSHp3hv7P8MqIHFviz8ANJfr6UMlNKeUySW+fsIkk/7HJvQO+/3pv72bardvtQkhNLKQePDoE7cfTYbnV52Z5nJHlLku9P8rellM/WWp9Ua/18KaUm+UKGu9D90vYzHJdSLk7yi7XWGzI8K9Z7SymvSfJPGX7I0J17Hc9QSlmf4SUpnpLhfvLvK6Ukw//u/qzW+sGpj5L5vKGU8ogMdzn+apIXJPecv9FZdM/M8IfKXkk21Fo/39F4+U9vTbImw13nkuRTtdYXeu/1167eS6WUVyX5TK31Axl+nr27lHJ1hifVOKW7ETPHTyY5Ncm/lFI+O3rsZUl+KElqrW/P8BcQLyqlbElyV5JT/DKiN+b9WVhKeWGyY/4uzvCSPVdneNme53Y0VuYx+kXEEzP6d8rosbnz5/3XE6WUCzJcaZ0tpVyX4ZmLfy9JLaU8P8m/Z3gi2ZRSjknywlrrL9ZabymlvDrDX/4myatqrTufXOpeZgYD8wwAAEB7+rjLMQAAAOyRoAUAAKBJghYAAIAmCVoAAACaJGgBAABokqAFAACgSYIWAACAJglaAAAAmvT/AUZAFC2ZVMIxAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1152x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Extract samples from posterior\n",
    "posterior_samples = mcmc.get_samples()\n",
    "\n",
    "sns.distplot(posterior_samples[\"alpha\"])\n",
    "sns.distplot(posterior_samples[\"sigma\"])\n",
    "\n",
    "# Alternate plotting due to deprecated distplot-function\n",
    "#sns.histplot(data=posterior_samples[\"alpha\"], kde=True, stat='density', color=next(palette), element=\"step\")\n",
    "#sns.histplot(data=posterior_samples[\"sigma\"], kde=True, stat='density', color=next(palette), element=\"step\")\n",
    "\n",
    "plt.legend([\"alpha\", \"sigma\"])\n",
    "plt.axis([-10,10,0,5])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000])\n",
      "torch.Size([1000, 15])\n"
     ]
    }
   ],
   "source": [
    "print(posterior_samples[\"alpha\"].shape)\n",
    "print(posterior_samples[\"beta\"].shape)\n",
    "\n",
    "beta_hat=torch.mean(posterior_samples[\"beta\"], axis=0)\n",
    "alpha_hat=torch.mean(posterior_samples[\"alpha\"], axis=0)\n",
    "\n",
    "# Compute predictions\n",
    "y_hat = np.mean(posterior_samples[\"alpha\"].numpy().T + np.dot(X_test, posterior_samples[\"beta\"].numpy().T), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CorrCoef: 0.288\n",
      "MAE: 21.034\n",
      "RMSE: 36.340\n",
      "R2: 0.083\n"
     ]
    }
   ],
   "source": [
    "# Convert back to the original scale\n",
    "preds = y_hat * y_test_std + y_test_mean\n",
    "y_true = y_test * y_test_std + y_test_mean\n",
    "corr, mae, rae, rmse, r2 = compute_error(y_true, preds)\n",
    "print(\"CorrCoef: %.3f\\nMAE: %.3f\\nRMSE: %.3f\\nR2: %.3f\" % (corr, mae, rmse, r2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pyro: Train on full dataset using Stochastic Variational Inference (SVI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for Pyro model\n",
    "X_train_torch = torch.tensor(X_train).float()\n",
    "y_train_torch = torch.tensor(y_train).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define guide function\n",
    "guide = AutoMultivariateNormal(model)\n",
    "\n",
    "# Reset parameter values\n",
    "pyro.clear_param_store()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the number of optimization steps\n",
    "n_steps = 4000\n",
    "\n",
    "# Setup the optimizer\n",
    "adam_params = {\"lr\": 0.001} # learning rate (lr) of optimizer\n",
    "optimizer = ClippedAdam(adam_params)\n",
    "\n",
    "# Setup the inference algorithm\n",
    "elbo = Trace_ELBO(num_particles=1)\n",
    "svi = SVI(model, guide, optimizer, loss=elbo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] ELBO: 108805.5\n",
      "[100] ELBO: 97313.8\n",
      "[200] ELBO: 93261.9\n",
      "[300] ELBO: 93635.5\n",
      "[400] ELBO: 94182.6\n",
      "[500] ELBO: 89517.2\n",
      "[600] ELBO: 84914.8\n",
      "[700] ELBO: 72486.9\n",
      "[800] ELBO: 76502.7\n",
      "[900] ELBO: 74155.0\n",
      "[1000] ELBO: 75196.9\n",
      "[1100] ELBO: 68537.7\n",
      "[1200] ELBO: 64189.5\n",
      "[1300] ELBO: 56700.5\n",
      "[1400] ELBO: 64563.1\n",
      "[1500] ELBO: 57034.7\n",
      "[1600] ELBO: 54482.4\n",
      "[1700] ELBO: 51326.6\n",
      "[1800] ELBO: 52857.5\n",
      "[1900] ELBO: 52318.3\n",
      "[2000] ELBO: 51898.1\n",
      "[2100] ELBO: 50423.7\n",
      "[2200] ELBO: 50591.0\n",
      "[2300] ELBO: 50414.7\n",
      "[2400] ELBO: 50524.8\n",
      "[2500] ELBO: 50497.9\n",
      "[2600] ELBO: 50512.6\n",
      "[2700] ELBO: 50394.7\n",
      "[2800] ELBO: 50256.7\n",
      "[2900] ELBO: 50246.1\n",
      "[3000] ELBO: 50400.7\n",
      "[3100] ELBO: 50260.3\n",
      "[3200] ELBO: 50246.0\n",
      "[3300] ELBO: 50262.5\n",
      "[3400] ELBO: 50249.3\n",
      "[3500] ELBO: 50206.6\n",
      "[3600] ELBO: 50253.8\n",
      "[3700] ELBO: 50180.3\n",
      "[3800] ELBO: 50215.0\n",
      "[3900] ELBO: 50244.0\n"
     ]
    }
   ],
   "source": [
    "# Do gradient steps\n",
    "for step in range(n_steps):\n",
    "    elbo = svi.step(X_train_torch, y_train_torch)\n",
    "    if step % 100 == 0:\n",
    "        print(\"[%d] ELBO: %.1f\" % (step, elbo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyro.infer import Predictive\n",
    "\n",
    "predictive = Predictive(model, guide=guide, num_samples=1000,\n",
    "                        return_sites=(\"alpha\", \"beta\", \"sigma\"))\n",
    "samples = predictive(X_train_torch, y_train_torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CorrCoef: 0.288\n",
      "MAE: 21.039\n",
      "RMSE: 36.339\n",
      "R2: 0.083\n"
     ]
    }
   ],
   "source": [
    "alpha_samples = samples[\"alpha\"].detach().numpy()\n",
    "beta_samples = samples[\"beta\"].detach().numpy()\n",
    "y_hat = np.mean(alpha_samples.T + np.dot(X_test, beta_samples[:,0].T), axis=1)\n",
    "\n",
    "# Convert back to the original scale\n",
    "preds = y_hat * y_test_std + y_test_mean\n",
    "y_true = y_test * y_test_std + y_test_mean\n",
    "corr, mae, rae, rmse, r2 = compute_error(y_true, preds)\n",
    "print(\"CorrCoef: %.3f\\nMAE: %.3f\\nRMSE: %.3f\\nR2: %.3f\" % (corr, mae, rmse, r2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.3 Pyro: Heteroscedastic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def heteroscedastic_model(X, obs=None):\n",
    "    alpha_mu = pyro.sample(\"alpha_mu\", dist.Normal(0., 1.))                 # Prior for the bias/intercept of the mean\n",
    "    beta_mu  = pyro.sample(\"beta_mu\", dist.Normal(torch.zeros(X.shape[1]), \n",
    "                                               torch.ones(X.shape[1])).to_event())     # Priors for the regression coeffcients of the mean\n",
    "    alpha_v = pyro.sample(\"alpha_v\", dist.Normal(0., 1.))                   # Prior for the bias/intercept of the variance\n",
    "    beta_v  = pyro.sample(\"beta_v\", dist.Normal(torch.zeros(X.shape[1]), \n",
    "                                               torch.ones(X.shape[1])).to_event())     # Priors for the regression coeffcients of the variance\n",
    "    \n",
    "    with pyro.plate(\"data\"):\n",
    "        y = pyro.sample(\"y\", dist.Normal(alpha_mu + X.matmul(beta_mu), torch.exp(alpha_v + X.matmul(beta_v))), obs=obs)\n",
    "        \n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for Pyro model\n",
    "X_train_torch = torch.tensor(X_train).float()\n",
    "y_train_torch = torch.tensor(y_train).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] ELBO: 81964182.7\n",
      "[200] ELBO: 143554.9\n",
      "[400] ELBO: 58855.8\n",
      "[600] ELBO: 57575.5\n",
      "[800] ELBO: 54087.1\n",
      "[1000] ELBO: 58191.1\n",
      "[1200] ELBO: 50152.9\n",
      "[1400] ELBO: 48922.5\n",
      "[1600] ELBO: 48997.6\n",
      "[1800] ELBO: 49260.6\n",
      "[2000] ELBO: 48928.1\n",
      "[2200] ELBO: 47794.5\n",
      "[2400] ELBO: 47614.5\n",
      "[2600] ELBO: 47732.0\n",
      "[2800] ELBO: 47538.7\n",
      "[3000] ELBO: 47796.8\n",
      "[3200] ELBO: 47459.3\n",
      "[3400] ELBO: 47485.2\n",
      "[3600] ELBO: 47447.1\n",
      "[3800] ELBO: 47338.1\n",
      "[4000] ELBO: 47385.9\n",
      "[4200] ELBO: 47373.8\n",
      "[4400] ELBO: 47308.8\n",
      "[4600] ELBO: 47287.5\n",
      "[4800] ELBO: 47307.2\n",
      "[5000] ELBO: 47271.7\n",
      "[5200] ELBO: 47309.7\n",
      "[5400] ELBO: 47265.3\n",
      "[5600] ELBO: 47270.1\n",
      "[5800] ELBO: 47274.4\n",
      "[6000] ELBO: 47253.6\n",
      "[6200] ELBO: 47253.6\n",
      "[6400] ELBO: 47247.2\n",
      "[6600] ELBO: 47271.9\n",
      "[6800] ELBO: 47249.4\n",
      "[7000] ELBO: 47287.0\n",
      "[7200] ELBO: 47269.4\n",
      "[7400] ELBO: 47254.4\n",
      "[7600] ELBO: 47275.6\n",
      "[7800] ELBO: 47251.3\n"
     ]
    }
   ],
   "source": [
    "# Define guide function\n",
    "guide = AutoMultivariateNormal(heteroscedastic_model)\n",
    "\n",
    "# Reset parameter values\n",
    "pyro.clear_param_store()\n",
    "\n",
    "# Define the number of optimization steps\n",
    "n_steps = 8000\n",
    "\n",
    "# Setup the optimizer\n",
    "adam_params = {\"lr\": 0.001} # learning rate (lr) of optimizer\n",
    "optimizer = ClippedAdam(adam_params)\n",
    "\n",
    "# Setup the inference algorithm\n",
    "elbo = Trace_ELBO(num_particles=1)\n",
    "svi = SVI(heteroscedastic_model, guide, optimizer, loss=elbo)\n",
    "\n",
    "# Do gradient steps\n",
    "for step in range(n_steps):\n",
    "    elbo = svi.step(X_train_torch, y_train_torch)\n",
    "    if step % 200 == 0:\n",
    "        print(\"[%d] ELBO: %.1f\" % (step, elbo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyro.infer import Predictive\n",
    "\n",
    "predictive = Predictive(heteroscedastic_model, guide=guide, num_samples=1000,\n",
    "                        return_sites=(\"alpha_mu\", \"beta_mu\", \"alpha_v\", \"beta_v\"))\n",
    "samples = predictive(X_train_torch, y_train_torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CorrCoef: 0.285\n",
      "MAE: 20.999\n",
      "RMSE: 36.477\n",
      "R2: 0.076\n"
     ]
    }
   ],
   "source": [
    "alpha_samples = samples[\"alpha_mu\"].detach().numpy()\n",
    "beta_samples = samples[\"beta_mu\"].detach().numpy()\n",
    "y_hat = np.mean(alpha_samples.T + np.dot(X_test, beta_samples[:,0].T), axis=1)\n",
    "\n",
    "# convert back to the original scale\n",
    "preds = y_hat * y_test_std + y_test_mean\n",
    "y_true = y_test * y_test_std + y_test_mean\n",
    "\n",
    "corr, mae, rae, rmse, r2 = compute_error(y_true, preds)\n",
    "print(\"CorrCoef: %.3f\\nMAE: %.3f\\nRMSE: %.3f\\nR2: %.3f\" % (corr, mae, rmse, r2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_v_samples = samples[\"alpha_v\"].detach().numpy()\n",
    "beta_v_samples = samples[\"beta_v\"].detach().numpy()\n",
    "sigma_hat = np.mean(np.exp(alpha_v_samples.T + np.dot(X_test, beta_v_samples[:,0].T)), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.755 0.544 0.928 0.619 0.888 0.591 0.815 1.189 0.765 0.973]\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(precision=3)\n",
    "print(sigma_hat[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NNET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(54180, 15)\n"
     ]
    }
   ],
   "source": [
    "X = df.drop([\"DEP_DELAY\"], axis=1)\n",
    "print(X.shape)\n",
    "X = X.to_numpy()\n",
    "\n",
    "\n",
    "y = df[\"DEP_DELAY\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "# standardize input features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FFNN(torch.nn.Module):\n",
    "    def __init__(self, n_in, n_hidden, n_out):\n",
    "        super(FFNN, self).__init__()\n",
    "        \n",
    "        # Architecture\n",
    "        self.in_layer = torch.nn.Linear(n_in, n_hidden)\n",
    "        self.h_layer = torch.nn.Linear(n_hidden, n_hidden)\n",
    "        self.out_layer = torch.nn.Linear(n_hidden, n_out)\n",
    "        \n",
    "        # Activation functions\n",
    "        self.tanh = torch.nn.Tanh()\n",
    "        \n",
    "    def forward(self, X):\n",
    "        # Forward pass\n",
    "        X = self.tanh(self.in_layer(X))\n",
    "        X = self.tanh(self.h_layer(X))\n",
    "        X = self.out_layer(X)\n",
    "        \n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nnet_model(X, y=None):\n",
    "    # Initialize the neural network from PyTorch \n",
    "    torch_model = FFNN(n_in=X.shape[1], n_hidden=4, n_out=1) \n",
    "    \n",
    "    # Convert the PyTorch neural net into a Pyro model with priors\n",
    "    priors = {} # Priors for the neural model\n",
    "    for name, par in torch_model.named_parameters():     # Loop over all neural network parameters\n",
    "        priors[name] = dist.Normal(torch.zeros(*par.shape), torch.ones(*par.shape)).to_event() # Each parameter has a N(0, 1) prior\n",
    "    \n",
    "    bayesian_model = pyro.random_module('bayesian_model', torch_model, priors) # Make this model and these priors a Pyro model\n",
    "    sampled_model = bayesian_model()                                           # Initialize the model\n",
    "    \n",
    "    # The generative process\n",
    "    with pyro.plate(\"observations\"):\n",
    "        prediction_mean = sampled_model(X).squeeze(-1) # Feed-forward the design matrix X through the neural network\n",
    "        y = pyro.sample(\"obs\", dist.Normal(prediction_mean, 0.1), obs=y)\n",
    "        \n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for Pyro by converting it into PyTorch tensors\n",
    "X = torch.tensor(X).float()\n",
    "y = torch.tensor(y).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define guide function\n",
    "guide = AutoDiagonalNormal(nnet_model)\n",
    "\n",
    "# Reset parameter values\n",
    "pyro.clear_param_store()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] ELBO: 4451795098.4\n",
      "[500] ELBO: 3943992469.1\n",
      "[1000] ELBO: 3713619224.1\n",
      "[1500] ELBO: 3635634965.5\n",
      "[2000] ELBO: 3587111816.5\n",
      "[2500] ELBO: 3528927022.8\n",
      "[3000] ELBO: 3449505276.6\n",
      "[3500] ELBO: 3426802283.8\n",
      "[4000] ELBO: 3411880151.0\n",
      "[4500] ELBO: 3394207828.8\n",
      "[5000] ELBO: 3378704802.4\n",
      "[5500] ELBO: 3363890703.4\n",
      "[6000] ELBO: 3293962787.9\n",
      "[6500] ELBO: 3370693132.2\n",
      "[7000] ELBO: 3256527538.7\n",
      "[7500] ELBO: 3254951747.9\n",
      "[8000] ELBO: 3300539841.1\n",
      "[8500] ELBO: 3288335911.2\n",
      "[9000] ELBO: 3234804094.7\n",
      "[9500] ELBO: 3232599258.3\n"
     ]
    }
   ],
   "source": [
    "# Define the number of optimization steps\n",
    "n_steps = 10000\n",
    "\n",
    "# Setup the optimizer\n",
    "adam_params = {\"lr\": 0.01}\n",
    "optimizer = Adam(adam_params)\n",
    "\n",
    "# Setup the inference algorithm\n",
    "elbo = Trace_ELBO(num_particles=1)\n",
    "svi = SVI(nnet_model, guide, optimizer, loss=elbo)\n",
    "\n",
    "# Do gradient steps\n",
    "for step in range(n_steps):\n",
    "    elbo = svi.step(X, y)\n",
    "    if step % 500 == 0:\n",
    "        print(\"[%d] ELBO: %.1f\" % (step, elbo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jcrl\\AppData\\Local\\Temp\\ipykernel_13444\\327537019.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_test = torch.tensor(X_test).float()\n"
     ]
    }
   ],
   "source": [
    "# Prepare test data for Pyro\n",
    "X_test = torch.tensor(X_test).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyro.infer import Predictive\n",
    "\n",
    "# Make predictions for test set\n",
    "predictive = Predictive(nnet_model, guide=guide, num_samples=1000,\n",
    "                        return_sites=(\"obs\", \"_RETURN\"))\n",
    "samples = predictive(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 32.84330776734985\n"
     ]
    }
   ],
   "source": [
    "y_pred = samples[\"obs\"].mean(axis=0).detach().numpy()\n",
    "mae = np.mean(np.abs(y_test - y_pred))\n",
    "print(\"MAE:\", mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "all the input array dimensions for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 1 and the array at index 1 has size 17880",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\jcrl\\Desktop\\ModelML_project\\Linear_model.ipynb Cell 42'\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jcrl/Desktop/ModelML_project/Linear_model.ipynb#ch0000039?line=2'>3</a>\u001b[0m \u001b[39m# convert back to the original scale\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jcrl/Desktop/ModelML_project/Linear_model.ipynb#ch0000039?line=3'>4</a>\u001b[0m preds \u001b[39m=\u001b[39m y_hat \u001b[39m*\u001b[39m y_test_std \u001b[39m+\u001b[39m y_test_mean\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/jcrl/Desktop/ModelML_project/Linear_model.ipynb#ch0000039?line=5'>6</a>\u001b[0m corr, mae, rae, rmse, r2 \u001b[39m=\u001b[39m compute_error(y_test, samples)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jcrl/Desktop/ModelML_project/Linear_model.ipynb#ch0000039?line=6'>7</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mCorrCoef: \u001b[39m\u001b[39m%.3f\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39mMAE: \u001b[39m\u001b[39m%.3f\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39mRMSE: \u001b[39m\u001b[39m%.3f\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39mR2: \u001b[39m\u001b[39m%.3f\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (corr, mae, rmse, r2))\n",
      "\u001b[1;32mc:\\Users\\jcrl\\Desktop\\ModelML_project\\Linear_model.ipynb Cell 8'\u001b[0m in \u001b[0;36mcompute_error\u001b[1;34m(trues, predicted)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jcrl/Desktop/ModelML_project/Linear_model.ipynb#ch0000007?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcompute_error\u001b[39m(trues, predicted):\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/jcrl/Desktop/ModelML_project/Linear_model.ipynb#ch0000007?line=1'>2</a>\u001b[0m     corr \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mcorrcoef(predicted, trues)[\u001b[39m0\u001b[39m,\u001b[39m1\u001b[39m]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jcrl/Desktop/ModelML_project/Linear_model.ipynb#ch0000007?line=2'>3</a>\u001b[0m     mae \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mmean(np\u001b[39m.\u001b[39mabs(predicted \u001b[39m-\u001b[39m trues))\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jcrl/Desktop/ModelML_project/Linear_model.ipynb#ch0000007?line=3'>4</a>\u001b[0m     rae \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39msum(np\u001b[39m.\u001b[39mabs(predicted \u001b[39m-\u001b[39m trues)) \u001b[39m/\u001b[39m np\u001b[39m.\u001b[39msum(np\u001b[39m.\u001b[39mabs(trues \u001b[39m-\u001b[39m np\u001b[39m.\u001b[39mmean(trues)))\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mcorrcoef\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\jcrl\\miniconda3\\envs\\ModelML\\lib\\site-packages\\numpy\\lib\\function_base.py:2821\u001b[0m, in \u001b[0;36mcorrcoef\u001b[1;34m(x, y, rowvar, bias, ddof, dtype)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/jcrl/miniconda3/envs/ModelML/lib/site-packages/numpy/lib/function_base.py?line=2816'>2817</a>\u001b[0m \u001b[39mif\u001b[39;00m bias \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m np\u001b[39m.\u001b[39m_NoValue \u001b[39mor\u001b[39;00m ddof \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m np\u001b[39m.\u001b[39m_NoValue:\n\u001b[0;32m   <a href='file:///c%3A/Users/jcrl/miniconda3/envs/ModelML/lib/site-packages/numpy/lib/function_base.py?line=2817'>2818</a>\u001b[0m     \u001b[39m# 2015-03-15, 1.10\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/jcrl/miniconda3/envs/ModelML/lib/site-packages/numpy/lib/function_base.py?line=2818'>2819</a>\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\u001b[39m'\u001b[39m\u001b[39mbias and ddof have no effect and are deprecated\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m   <a href='file:///c%3A/Users/jcrl/miniconda3/envs/ModelML/lib/site-packages/numpy/lib/function_base.py?line=2819'>2820</a>\u001b[0m                   \u001b[39mDeprecationWarning\u001b[39;00m, stacklevel\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m)\n\u001b[1;32m-> <a href='file:///c%3A/Users/jcrl/miniconda3/envs/ModelML/lib/site-packages/numpy/lib/function_base.py?line=2820'>2821</a>\u001b[0m c \u001b[39m=\u001b[39m cov(x, y, rowvar, dtype\u001b[39m=\u001b[39;49mdtype)\n\u001b[0;32m   <a href='file:///c%3A/Users/jcrl/miniconda3/envs/ModelML/lib/site-packages/numpy/lib/function_base.py?line=2821'>2822</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   <a href='file:///c%3A/Users/jcrl/miniconda3/envs/ModelML/lib/site-packages/numpy/lib/function_base.py?line=2822'>2823</a>\u001b[0m     d \u001b[39m=\u001b[39m diag(c)\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mcov\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\jcrl\\miniconda3\\envs\\ModelML\\lib\\site-packages\\numpy\\lib\\function_base.py:2615\u001b[0m, in \u001b[0;36mcov\u001b[1;34m(m, y, rowvar, bias, ddof, fweights, aweights, dtype)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/jcrl/miniconda3/envs/ModelML/lib/site-packages/numpy/lib/function_base.py?line=2612'>2613</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m rowvar \u001b[39mand\u001b[39;00m y\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m] \u001b[39m!=\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   <a href='file:///c%3A/Users/jcrl/miniconda3/envs/ModelML/lib/site-packages/numpy/lib/function_base.py?line=2613'>2614</a>\u001b[0m         y \u001b[39m=\u001b[39m y\u001b[39m.\u001b[39mT\n\u001b[1;32m-> <a href='file:///c%3A/Users/jcrl/miniconda3/envs/ModelML/lib/site-packages/numpy/lib/function_base.py?line=2614'>2615</a>\u001b[0m     X \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mconcatenate((X, y), axis\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m)\n\u001b[0;32m   <a href='file:///c%3A/Users/jcrl/miniconda3/envs/ModelML/lib/site-packages/numpy/lib/function_base.py?line=2616'>2617</a>\u001b[0m \u001b[39mif\u001b[39;00m ddof \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   <a href='file:///c%3A/Users/jcrl/miniconda3/envs/ModelML/lib/site-packages/numpy/lib/function_base.py?line=2617'>2618</a>\u001b[0m     \u001b[39mif\u001b[39;00m bias \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mconcatenate\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: all the input array dimensions for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 1 and the array at index 1 has size 17880"
     ]
    }
   ],
   "source": [
    "y_hat = np.mean(alpha_samples.T + np.dot(X_test, beta_samples[:,0].T), axis=1)\n",
    "\n",
    "# convert back to the original scale\n",
    "preds = y_hat * y_test_std + y_test_mean\n",
    "\n",
    "corr, mae, rae, rmse, r2 = compute_error(y_test, samples)\n",
    "print(\"CorrCoef: %.3f\\nMAE: %.3f\\nRMSE: %.3f\\nR2: %.3f\" % (corr, mae, rmse, r2))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f3449860fed0861a1e81fd060afa67eac864f2ca12d1913a45e827e462276ab2"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('ModelML')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
